# wrapper around curl to ensure 
# - auto-resume download until it completes
# - auto save file into correct directory
# ARGV[0] is the URL to download

require URI;
use File::Path;
use File::Basename;

$url = $ARGV[0];
print "Fetching $url\n";

# fetch header for Content-Length
open HDR_IN, "curl --head --silent $url |" or die "Unable to open header.";
while (<HDR_IN>) {
    if ($_ =~ /Content-Length: (\d*)/) {
	$content_length = $1;
	last;
    }
}

die "Content-Length not found in header." unless (defined($content_length));
print "$content_length";

$u = URI->new($url);
# parse URL to determine location to save data
$filename = $u->host . $u->path;
($name, $path, $suffix) = fileparse($filename, '\..*');
if ($name eq "") {
    $name = "00index";
    $suffix = ".html";
}
# make directory(s) if needed
mkpath("$path");

$filename = "$path$name$suffix";
print "Saving to $filename.\n";

# do curl until we have the whole file
$resume = 0;
while (-s $filename != $content_length)
{
    `curl --verbose --continue -output $filename $url`;    
    $resume ++;
}

print "Obtained file in $resume tries.\n";




